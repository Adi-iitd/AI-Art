# -*- coding: utf-8 -*-
"""Deep_Dream

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dnqQREjDbbkCzLtalmmVd6j7R5cxWHPH
"""

from google.colab import files; uploaded = files.upload(); 
for fn in uploaded.keys(): print('User uploaded file "{name}" with length {length} bytes'.format(name = fn, length = len(uploaded[fn])))

import numpy as np; np.random.seed(42); import tensorflow as tf; tf.set_random_seed(42); import os; import math;
import matplotlib.pyplot as plt; from IPython.display import Image, display; import PIL.Image; import random; 
from scipy.ndimage.filters import gaussian_filter; import urllib.request;  import scipy; 
import zipfile; import tarfile; import warnings; warnings.filterwarnings("ignore"); 

# %matplotlib inline

data_url  = "http://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip";
data_dir  = "inception_5h/"; path_graph_def = "tensorflow_inception_graph.pb";

def download_data(data_url, data_dir):
    
    file_name = data_url.split("/")[-1]; abs_file_path = os.path.join(data_dir, file_name);
    if not os.path.exists(abs_file_path):
        
        print("Downloading data");
        if not os.path.exists(data_dir): os.makedirs(data_dir);
        file_name, _ = urllib.request.urlretrieve(data_url, abs_file_path);
        
        if file_name.endswith(".zip"): zipfile.ZipFile(file = file_name, mode = "r").extractall(data_dir);
        elif file_name.endswith((".tgz", ".tar.tgz")): tarfile.open(file = file_name, mode = "r:gz").extractall(data_dir);
    
    else: print("Data has already been downloaded");
    return 

download_data(data_url, data_dir);

class Inception_Model():
  
    input_name = "input:0"; layer_names = ["conv2d0", "conv2d1", "conv2d2", "mixed3a", "mixed3b", "mixed4a", "mixed4b", "mixed4c", 
                                           "mixed4d", "mixed4e", "mixed5a", "mixed5b"];
    
    def __init__(self):
      
        self.graph = tf.Graph();
        with self.graph.as_default():
            
            path = os.path.join(data_dir, path_graph_def);
            with tf.gfile.GFile(path, "rb") as file:
                
                graph_def = tf.GraphDef(); graph_def.ParseFromString(file.read()); 
                tf.import_graph_def(graph_def, name = "");
                
            self.input_tensor = self.graph.get_tensor_by_name(self.input_name);
            self.layer_tensor = [self.graph.get_tensor_by_name(name + ":0") for name in self.layer_names];
    
    def create_feed_dict(self, image):
      
        image = np.expand_dims(image, axis = 0); feed_dict = {self.input_name: image};
        return feed_dict
      
    def get_gradient(self, tensor):
        
        with self.graph.as_default():
            
            tensor = tf.reduce_mean(tf.square(tensor)); gradient = tf.gradients(tensor, self.input_tensor)[0];
            return gradient

model = Inception_Model();

def open_image(filename): image = PIL.Image.open(filename); return np.float32(image);

def normalize(tensor): return (tensor - np.min(tensor))/(np.max(tensor) - np.min(tensor));

def save_image(image, filename):
    image = np.clip(image, 0, 255.0); image = image.astype(np.uint8);
    with open(filename, "wb") as file: PIL.Image.fromarray(image).save(file, "jpeg");
      
def plot_image(image):     
    image = np.clip(image, 0.0, 255.0); image = image.astype(np.uint8); display(PIL.Image.fromarray(image));

def plot_gradient(gradient): 
    norm_gradient = normalize(gradient); plt.imshow(norm_gradient, interpolation = 'bilinear'); plt.show();

def resize_image(image, size = None, factor = None):
  
    if factor is not None: size = np.array(image.shape[0:2])*factor; size = size.astype(int)
    else: size = size[0:2];
    
    size = tuple(reversed(size)); img = np.clip(image, 0.0, 255.0); img = img.astype(np.uint8)
    img = PIL.Image.fromarray(img); img_resized = img.resize(size, PIL.Image.LANCZOS)
    img_resized = np.float32(img_resized); return img_resized
  
  
def get_tile_size(num_pixels, tile_size = 400):
  
    num_tiles = max(1, num_pixels//tile_size); actual_tile_size = math.ceil(num_pixels/num_tiles); 
    return actual_tile_size;
  

def get_tiled_gradient(gradient, image, tile_size):
    
    grad = np.zeros_like(image); width, height, _ = image.shape;
    x_tile_size = get_tile_size(width, tile_size = 400); y_tile_size = get_tile_size(width, tile_size = 400);
    
    x_start = random.randint(-3*(x_tile_size//4), -1*(x_tile_size//4));
    while x_start < width:
        
        x_end = x_start + x_tile_size; min_x_start = max(0, x_start); max_x_end = min(x_end, width);
        y_start = random.randint(-3*(y_tile_size//4), -1*(y_tile_size//4));
        while y_start < height:
          
            y_end = y_start + y_tile_size; min_y_start = max(0, y_start); max_y_end = min(y_end, height);
            tiled_img = image[min_x_start:max_x_end, min_y_start:max_y_end, :];
            feed_dict = model.create_feed_dict(image = tiled_img);
            
            g = sess.run(gradient, feed_dict = feed_dict); g /= (np.std(g) + 1e-8);
            grad[min_x_start:max_x_end, min_y_start:max_y_end, :] = g;
            
            y_start = y_end;
        
        x_start = x_end;
    
    return grad

def optimize_image(tensor, image, num_iterations, step_size, tile_size, show_gradient = False):
    
    img_copy = image.copy(); print("Before:"); plot_image(img_copy);
    print("Pre-processing Image"); gradient = model.get_gradient(tensor);
    for iter_ in range(num_iterations):
        
        grad = get_tiled_gradient(gradient, img_copy, tile_size); sigma = (4.0*iter_)/num_iterations + 0.5;
        smoothed_grad_1 = gaussian_filter(grad, 0.5*sigma); smoothed_grad_2 = gaussian_filter(grad, 1.0*sigma);
        smoothed_grad_3 = gaussian_filter(grad, 2.0*sigma); grad = (smoothed_grad_1 + smoothed_grad_2 + smoothed_grad_3);
        scaled_step_size = step_size / (np.std(grad) + 1e-8); img_copy += grad*scaled_step_size;
        
        if show_gradient: plot_gradient(grad);
    
    print("After:"); plot_image(img_copy); return img_copy

def recursive_optimize(tensor, image, num_repeats = 5, rescale_factor = 0.75, blend = 0.25, num_iterations = 25, step_size = 3.0, tile_size = 400):
  
    if num_repeats > 0:
      
        sigma = 0.5; img_blur = gaussian_filter(image, sigma = (sigma, sigma, 0));
        img_downscaled = resize_image(img_blur, factor = rescale_factor);
        img_result = recursive_optimize(tensor, img_downscaled, num_repeats - 1, rescale_factor, blend , num_iterations, step_size, tile_size);
        
        img_upscaled = resize_image(img_result, size = image.shape);
        image = blend*image + (1.0 - blend)*img_upscaled; print(f"Recursive_level: {num_repeats}");
    
    img_result = optimize_image(tensor, image, num_iterations, step_size, tile_size)
    return img_result;

image = open_image("./Tony_Stark.jpg"); sess = tf.InteractiveSession(graph = model.graph); tensor = model.layer_tensor[7];
img_result = recursive_optimize(tensor, image, num_iterations = 25, step_size = 3.0, rescale_factor = 0.75, num_repeats = 5, blend = 0.25);

save_image(img_result, "./Layer_4.jpg"); from google.colab import files; files.download('./Layer_4.jpg')



